![微信截图_20240428160207](https://github.com/user-attachments/assets/003fda46-1c33-4de8-8b31-73003174695b)![微信截图_20240428160226](https://github.com/user-attachments/assets/7d3e2210-9461-43cd-bcac-03c383776f29)# Crossroads-Phantom Opera

"Crossroads-Phantom Opera" is an experimental performance that combines augmented reality technology with opera performance. It explores the possibilities of integrating cutting-edge technology with traditional performances, based on the classic Chinese Peking opera "Crossroads". In this performance, AR technology is used to recreate one of the core characters as a virtual phantom, who interacts with real opera actors during rehearsals and performances.

## Introduction

The"Crossroads"  is a traditional Peking Opera played by martial artists.The context of this play was a fight in the dark inn, which meant that even when facing each other, the two performers needed to act as if they were unable to see each other.

In our project, we deliberately made performer not wear the ar headset, so that he could not see the virtual phantom, which just right restored the status and relationship between the two in the original play. Additionally, performer needed to memorize the whole set of movements of both parties and realize the interactions during this "cross-reality" performance.

## production

### Time Synchronization

Performance need to ensure the consistency of the opera image in the eyes of all audience. In addition, we cannot expect and ask all our participants to open the program at the same time to realize this precise requirement.

<img width="680" alt="Screenshot 2024-04-28 at 16 17 16" src="https://github.com/user-attachments/assets/ff24c17e-dd14-4d3b-8f05-f5c53e3a528d">

<img width="680" alt="Screenshot 2024-04-28 at 16 59 28" src="https://github.com/user-attachments/assets/361033ae-a799-4985-8be5-3e82c5fcd174">

### Spatial Synchronization

Immersal which is a spatial scanning technique is utilized to build the venue information of the performance into the project in advance. In our tests we used a simple pedestal with highly recognizable patterns as the basis of scanning to ensure maximum stability of spatial recognition. Ultimately, Spatial synchronization is achieved when all devices are based on one accurate spatial information.

<img width="1364" alt="Screenshot 2024-04-02 at 22 27 54" src="https://github.com/user-attachments/assets/a59d5a71-b831-4247-9de8-7829e4fb9ef0">

#### Spatial Technology Stability Testing

It is possible to achieve almost no error in the stationary standing state, but there is a drift under movement, and this drift increases with movement, with a maximum variation of about 4cm. It takes 3-4 seconds to auto-calibrate after a drift. Moreover, instability occurs at roughly 6m from the center of stage. And it has been tested that having radar on the phone will improve the stability.

<img width="503" alt="Screenshot 2024-07-12 at 11 17 35" src="https://github.com/user-attachments/assets/0be7192c-dfa0-437c-be4f-9eeda08d09e8">
<img width="503" alt="Screenshot 2024-07-12 at 11 17 35" src="https://github.com/user-attachments/assets/028ccbd2-61c2-4289-802e-fc604451f97c">

<img width="700" alt="Screenshot 2024-07-12 at 11 17 35" src="https://github.com/user-attachments/assets/aacce019-205e-4e5d-aab6-2410915c6246">
<img width="307" alt="Screenshot 2024-07-12 at 11 17 35" src="https://github.com/user-attachments/assets/e2b62859-989d-4108-9f2c-79d74d75d5e0">


